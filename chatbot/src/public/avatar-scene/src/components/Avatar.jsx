/*
Auto-generated by: https://github.com/pmndrs/gltfjsx
Command: npx gltfjsx@6.2.3 public/models/64f1a714fe61576b46f27ca2.glb -o src/components/Avatar.jsx -k -r public
*/

import { useAnimations, useGLTF } from "@react-three/drei";
import { useFrame } from "@react-three/fiber";
import { button, useControls } from "leva";
import React, { useEffect, useRef, useState } from "react";

import * as THREE from "three";
import { useChat } from "../hooks/useChat";

const facialExpressions = {
  default: {},
  smile: {
    browInnerUp: 0.17,
    eyeSquintLeft: 0.4,
    eyeSquintRight: 0.44,
    noseSneerLeft: 0.1700000727403593,
    noseSneerRight: 0.14000002836874015,
    mouthPressLeft: 0.61,
    mouthPressRight: 0.41000000000000003,
  },
  funnyFace: {
    jawLeft: 0.63,
    mouthPucker: 0.53,
    noseSneerLeft: 1,
    noseSneerRight: 0.39,
    mouthLeft: 1,
    eyeLookUpLeft: 1,
    eyeLookUpRight: 1,
    cheekPuff: 0.9999924982764238,
    mouthDimpleLeft: 0.414743888682652,
    mouthRollLower: 0.32,
    mouthSmileLeft: 0.35499733688813034,
    mouthSmileRight: 0.35499733688813034,
  },
  sad: {
    mouthFrownLeft: 1,
    mouthFrownRight: 1,
    mouthShrugLower: 0.78341,
    browInnerUp: 0.452,
    eyeSquintLeft: 0.72,
    eyeSquintRight: 0.75,
    eyeLookDownLeft: 0.5,
    eyeLookDownRight: 0.5,
    jawForward: 1,
  },
  surprised: {
    eyeWideLeft: 0.5,
    eyeWideRight: 0.5,
    jawOpen: 0.351,
    mouthFunnel: 1,
    browInnerUp: 1,
  },
  angry: {
    browDownLeft: 1,
    browDownRight: 1,
    eyeSquintLeft: 1,
    eyeSquintRight: 1,
    jawForward: 1,
    jawLeft: 1,
    mouthShrugLower: 1,
    noseSneerLeft: 1,
    noseSneerRight: 0.42,
    eyeLookDownLeft: 0.16,
    eyeLookDownRight: 0.16,
    cheekSquintLeft: 1,
    cheekSquintRight: 1,
    mouthClose: 0.23,
    mouthFunnel: 0.63,
    mouthDimpleRight: 1,
  },
  crazy: {
    browInnerUp: 0.9,
    jawForward: 1,
    noseSneerLeft: 0.5700000000000001,
    noseSneerRight: 0.51,
    eyeLookDownLeft: 0.39435766259644545,
    eyeLookUpRight: 0.4039761421719682,
    eyeLookInLeft: 0.9618479575523053,
    eyeLookInRight: 0.9618479575523053,
    jawOpen: 0.9618479575523053,
    mouthDimpleLeft: 0.9618479575523053,
    mouthDimpleRight: 0.9618479575523053,
    mouthStretchLeft: 0.27893590769016857,
    mouthStretchRight: 0.2885543872656917,
    mouthSmileLeft: 0.5578718153803371,
    mouthSmileRight: 0.38473918302092225,
    tongueOut: 0.9618479575523053,
  },
};

const corresponding = {
  A: "viseme_PP",
  B: "viseme_kk",
  C: "viseme_I",
  D: "viseme_AA",
  E: "viseme_O",
  F: "viseme_U",
  G: "viseme_FF",
  H: "viseme_TH",
  X: "viseme_PP",
};

let setupMode = false;

export function Avatar(props) {
  const { nodes, materials, scene } = useGLTF(
    "/avatar/models/685424ed261493e82da26cc9.glb"
  );

  const { message, onMessagePlayed, chat } = useChat();

  const [lipsync, setLipsync] = useState();
  const [animation, setAnimation] = useState("Standing Idle");
  const [facialExpression, setFacialExpression] = useState("");
  const [audio, setAudio] = useState();
  const [isSpeaking, setIsSpeaking] = useState(false);
  // Removed currentTalkingAnimation - we'll only use Talking_1

  useEffect(() => {
    console.log('ðŸŽµ Avatar received message:', message);
    if (!message) {
      console.log('ðŸŽµ No message, stopping speech and setting idle');
      setIsSpeaking(false);
      setAnimation("Standing Idle");
      return;
    }
    
    console.log('ðŸŽµ Processing message with audio and lipsync');
    setFacialExpression(message.facialExpression);
    setLipsync(message.lipsync);
    
    // Stop any existing audio first to prevent duplicates
    if (audio && !audio.paused) {
      console.log('ðŸŽµ Stopping previous audio to prevent overlap');
      audio.pause();
      audio.currentTime = 0;
    }
    
    // Create and play audio element
    const newAudio = new Audio("data:audio/mp3;base64," + message.audio);
    setAudio(newAudio);
    
    console.log('ðŸŽµ Setting up audio event handlers for new audio');
    newAudio.volume = 1;
    
    // Start speaking animation when audio starts playing
    newAudio.onplay = () => {
      console.log('ðŸŽµ Audio started playing - enabling talking animations');
      setIsSpeaking(true);
    };
    
    // Handle audio end event
    newAudio.onended = () => {
      console.log('ðŸŽµ Audio ended - disabling talking animations');
      setIsSpeaking(false);
      onMessagePlayed();
      // Send message to main chatbot to hide stop button
      if (window.parent && window.parent !== window) {
        window.parent.postMessage({
          type: 'avatar_tts_ended'
        }, '*');
        console.log('ðŸŽµ Avatar TTS ended, notified main chatbot');
      }
    };
    
    // Error handling for audio playback
    newAudio.onerror = (error) => {
      console.error('ðŸŽµ Audio playback error:', error);
      setIsSpeaking(false);
    };
    
    // Play the audio
    newAudio.play().catch(error => {
      console.error('ðŸŽµ Audio play failed:', error);
      setIsSpeaking(false);
    });
    
    // Cleanup function to stop audio when component unmounts or new message arrives
    return () => {
      if (newAudio && !newAudio.paused) {
        console.log('ðŸŽµ Cleaning up audio on message change');
        newAudio.pause();
        newAudio.currentTime = 0;
      }
    };
  }, [message, onMessagePlayed]);

  const { animations } = useGLTF("/avatar/models/animations.glb");

  const group = useRef();
  const { actions, mixer } = useAnimations(animations, group);
  
  // Talking animation effect - simplified to only use Talking_1
  useEffect(() => {
    if (isSpeaking) {
      console.log('ðŸŽ¬ Starting Talking_1 animation (continuous loop)');
    } else {
      console.log('ðŸŽ¬ Stopping talking animation, returning to idle');
    }
  }, [isSpeaking]);
  
  // Animation state effect - handles playing the correct animation
  useEffect(() => {
    const animationToPlay = isSpeaking ? "Talking_1" : "Standing Idle";
    console.log('ðŸŽ¬ Setting animation to:', animationToPlay, 'isSpeaking:', isSpeaking);
    
    if (actions[animationToPlay]) {
      // Fade out all other animations first
      Object.keys(actions).forEach(actionName => {
        if (actionName !== animationToPlay && actions[actionName].isRunning()) {
          actions[actionName].fadeOut(0.2);
        }
      });
      
      // Play the target animation with loop for talking
      const action = actions[animationToPlay]
        .reset()
        .fadeIn(0.2);
      
      if (isSpeaking && animationToPlay === "Talking_1") {
        // Set talking animation to loop continuously and reduce intensity
        action.setLoop(2201); // LoopRepeat = 2201 in Three.js
        action.setEffectiveWeight(0.7); // Reduce intensity for more natural look
        console.log('ðŸŽ¬ Set Talking_1 to loop continuously with reduced weight');
      }
      
      action.play();
      console.log('ðŸŽ¬ Playing animation:', animationToPlay);
    } else if (actions["Idle"]) {
      // Fallback to "Idle" if target animation doesn't exist
      console.log('ðŸŽ¬ Fallback to Idle animation');
      Object.keys(actions).forEach(actionName => {
        if (actionName !== "Idle" && actions[actionName].isRunning()) {
          actions[actionName].fadeOut(0.2);
        }
      });
      actions["Idle"]
        .reset()
        .fadeIn(0.2)
        .play();
    }
    
    return () => {
      // Cleanup function to handle animation transitions
      if (actions[animationToPlay]) {
        actions[animationToPlay].fadeOut(0.2);
      }
    };
  }, [actions, mixer, isSpeaking]);

  const lerpMorphTarget = (target, value, speed = 0.1) => {
    scene.traverse((child) => {
      if (child.isSkinnedMesh && child.morphTargetDictionary) {
        const index = child.morphTargetDictionary[target];
        if (
          index === undefined ||
          child.morphTargetInfluences[index] === undefined
        ) {
          return;
        }
        child.morphTargetInfluences[index] = THREE.MathUtils.lerp(
          child.morphTargetInfluences[index],
          value,
          speed
        );

        if (!setupMode) {
          try {
            set({
              [target]: value,
            });
          } catch (e) {}
        }
      }
    });
  };

  const [blink, setBlink] = useState(false);
  const [winkLeft, setWinkLeft] = useState(false);
  const [winkRight, setWinkRight] = useState(false);

  // Simple mute handler for interrupting ongoing audio
  useEffect(() => {
    const handleMuteCommand = (event) => {
      if (event.data?.type === 'mute_immediate') {
        console.log('ðŸ”‡ Received immediate mute command');
        // Stop any currently playing audio
        if (audio && !audio.paused) {
          audio.pause();
          audio.currentTime = 0;
          console.log('ðŸ”‡ Audio stopped due to mute command');
        }
        
        // Stop speaking animations immediately
        console.log('ðŸ”‡ Stopping talking animations');
        setIsSpeaking(false);
        
        // Clear the current message queue and notify main chatbot
        onMessagePlayed();
        
        // Send message to main chatbot to hide stop button
        if (window.parent && window.parent !== window) {
          window.parent.postMessage({
            type: 'avatar_tts_ended'
          }, '*');
          console.log('ðŸ”‡ Sent avatar_tts_ended event after mute command');
        }
      } else if (event.data?.type === 'unmute') {
        console.log('ðŸ”Š Received unmute command - audio can play again');
        // Note: No action needed here, just logging for confirmation
        // Audio playbook will be controlled by the muted flag in TTS messages
      }
    };

    window.addEventListener('message', handleMuteCommand);
    return () => window.removeEventListener('message', handleMuteCommand);
  }, [audio, onMessagePlayed]);

  useFrame(() => {
    !setupMode &&
      Object.keys(nodes.EyeLeft.morphTargetDictionary).forEach((key) => {
        const mapping = facialExpressions[facialExpression];
        if (key === "eyeBlinkLeft" || key === "eyeBlinkRight") {
          return; // eyes wink/blink are handled separately
        }
        
        // During talking, override facial expressions that affect eye direction
        if (isSpeaking && (
          key.includes("eyeLook") || 
          key.includes("eyeWide") || 
          key.includes("eyeSquint")
        )) {
          return; // Skip these during talking to maintain eye lock
        }
        
        if (mapping && mapping[key]) {
          lerpMorphTarget(key, mapping[key], 0.1);
        } else {
          lerpMorphTarget(key, 0, 0.1);
        }
      });

    lerpMorphTarget("eyeBlinkLeft", blink || winkLeft ? 1 : 0, 0.5);
    lerpMorphTarget("eyeBlinkRight", blink || winkRight ? 1 : 0, 0.5);

    // Enhanced eye lock during talking animations
    if (isSpeaking) {
      // Aggressively reset ALL eye look directions to maintain forward gaze
      const eyeLookTargets = [
        "eyeLookUpLeft", "eyeLookUpRight",
        "eyeLookDownLeft", "eyeLookDownRight", 
        "eyeLookInLeft", "eyeLookInRight",
        "eyeLookOutLeft", "eyeLookOutRight"
      ];
      
      eyeLookTargets.forEach(target => {
        lerpMorphTarget(target, 0, 0.3); // Faster lerp for more responsive centering
      });
      
      // Also control eye width to prevent squinting during talking
      lerpMorphTarget("eyeWideLeft", 0.1, 0.2); // Slight wide eyes for engagement
      lerpMorphTarget("eyeWideRight", 0.1, 0.2);
      lerpMorphTarget("eyeSquintLeft", 0, 0.3);
      lerpMorphTarget("eyeSquintRight", 0, 0.3);
    }

    // LIPSYNC
    if (setupMode) {
      return;
    }

    const appliedMorphTargets = [];
    if (message && lipsync) {
      const currentAudioTime = audio?.currentTime || 0;
      for (let i = 0; i < lipsync.mouthCues.length; i++) {
        const mouthCue = lipsync.mouthCues[i];
        if (
          currentAudioTime >= mouthCue.start &&
          currentAudioTime <= mouthCue.end
        ) {
          appliedMorphTargets.push(corresponding[mouthCue.value]);
          lerpMorphTarget(corresponding[mouthCue.value], 1, 0.2);
          break;
        }
      }
    }

    Object.values(corresponding).forEach((value) => {
      if (appliedMorphTargets.includes(value)) {
        return;
      }
      lerpMorphTarget(value, 0, 0.1);
    });
  });

  useControls("FacialExpressions", {
    chat: button(() => chat()),
    winkLeft: button(() => {
      setWinkLeft(true);
      setTimeout(() => setWinkLeft(false), 300);
    }),
    winkRight: button(() => {
      setWinkRight(true);
      setTimeout(() => setWinkRight(false), 300);
    }),
    animation: {
      value: "Standing Idle", // Always show Standing Idle in controls
      options: animations.map((a) => a.name),
      onChange: (value) => {
        // Ignore animation changes - always keep Standing Idle
        console.log('ðŸŽ¬ Animation change ignored, keeping Standing Idle');
      },
    },
    facialExpression: {
      options: Object.keys(facialExpressions),
      onChange: (value) => setFacialExpression(value),
    },
    enableSetupMode: button(() => {
      setupMode = true;
    }),
    disableSetupMode: button(() => {
      setupMode = false;
    }),
    logMorphTargetValues: button(() => {
      const emotionValues = {};
      Object.keys(nodes.EyeLeft.morphTargetDictionary).forEach((key) => {
        if (key === "eyeBlinkLeft" || key === "eyeBlinkRight") {
          return; // eyes wink/blink are handled separately
        }
        const value =
          nodes.EyeLeft.morphTargetInfluences[
            nodes.EyeLeft.morphTargetDictionary[key]
          ];
        if (value > 0.01) {
          emotionValues[key] = value;
        }
      });
      console.log(JSON.stringify(emotionValues, null, 2));
    }),
  });

  const [, set] = useControls("MorphTarget", () =>
    Object.assign(
      {},
      ...Object.keys(nodes.EyeLeft.morphTargetDictionary).map((key) => {
        return {
          [key]: {
            label: key,
            value: 0,
            min: nodes.EyeLeft.morphTargetInfluences[
              nodes.EyeLeft.morphTargetDictionary[key]
            ],
            max: 1,
            onChange: (val) => {
              if (setupMode) {
                lerpMorphTarget(key, val, 1);
              }
            },
          },
        };
      })
    )
  );

  useEffect(() => {
    let blinkTimeout;
    const nextBlink = () => {
      blinkTimeout = setTimeout(() => {
        setBlink(true);
        setTimeout(() => {
          setBlink(false);
          nextBlink();
        }, 200);
      }, THREE.MathUtils.randInt(1000, 5000));
    };
    nextBlink();
    return () => clearTimeout(blinkTimeout);
  }, []);

  return (
    <group {...props} dispose={null} ref={group}>
      <primitive object={nodes.Hips} />
      <skinnedMesh
        name="Wolf3D_Body"
        geometry={nodes.Wolf3D_Body.geometry}
        material={materials.Wolf3D_Body}
        skeleton={nodes.Wolf3D_Body.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Outfit_Bottom"
        geometry={nodes.Wolf3D_Outfit_Bottom.geometry}
        material={materials.Wolf3D_Outfit_Bottom}
        skeleton={nodes.Wolf3D_Outfit_Bottom.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Outfit_Footwear"
        geometry={nodes.Wolf3D_Outfit_Footwear.geometry}
        material={materials.Wolf3D_Outfit_Footwear}
        skeleton={nodes.Wolf3D_Outfit_Footwear.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Outfit_Top"
        geometry={nodes.Wolf3D_Outfit_Top.geometry}
        material={materials.Wolf3D_Outfit_Top}
        skeleton={nodes.Wolf3D_Outfit_Top.skeleton}
      />
      <skinnedMesh
        name="Wolf3D_Hair"
        geometry={nodes.Wolf3D_Hair.geometry}
        material={materials.Wolf3D_Hair}
        skeleton={nodes.Wolf3D_Hair.skeleton}
      />
      <skinnedMesh
        name="EyeLeft"
        geometry={nodes.EyeLeft.geometry}
        material={materials.Wolf3D_Eye}
        skeleton={nodes.EyeLeft.skeleton}
        morphTargetDictionary={nodes.EyeLeft.morphTargetDictionary}
        morphTargetInfluences={nodes.EyeLeft.morphTargetInfluences}
      />
      <skinnedMesh
        name="EyeRight"
        geometry={nodes.EyeRight.geometry}
        material={materials.Wolf3D_Eye}
        skeleton={nodes.EyeRight.skeleton}
        morphTargetDictionary={nodes.EyeRight.morphTargetDictionary}
        morphTargetInfluences={nodes.EyeRight.morphTargetInfluences}
      />
      <skinnedMesh
        name="Wolf3D_Head"
        geometry={nodes.Wolf3D_Head.geometry}
        material={materials.Wolf3D_Skin}
        skeleton={nodes.Wolf3D_Head.skeleton}
        morphTargetDictionary={nodes.Wolf3D_Head.morphTargetDictionary}
        morphTargetInfluences={nodes.Wolf3D_Head.morphTargetInfluences}
      />
      <skinnedMesh
        name="Wolf3D_Teeth"
        geometry={nodes.Wolf3D_Teeth.geometry}
        material={materials.Wolf3D_Teeth}
        skeleton={nodes.Wolf3D_Teeth.skeleton}
        morphTargetDictionary={nodes.Wolf3D_Teeth.morphTargetDictionary}
        morphTargetInfluences={nodes.Wolf3D_Teeth.morphTargetInfluences}
      />
    </group>
  );
}

useGLTF.preload("/avatar/models/685424ed261493e82da26cc9.glb");
useGLTF.preload("/avatar/models/animations.glb");