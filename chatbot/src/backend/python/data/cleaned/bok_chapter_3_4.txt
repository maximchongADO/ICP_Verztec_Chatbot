--- Page 1 --- Page 1 of 14 Section 3 Internal Governance Dealing with internal governance structures & measures Chapter
3.4 Addressing Governance in Two Critical Sectors  Two highly-regulated sectors: Finance and Healthcare. Authors: Joey Pang & Dr Chong Yoke Sin & Dr James Yip
1. Banking & Finance:
1.1 FEAT Principles
1.2 Veritas Initiative
1.3 Digital Advisory Services
2. Healthcare:
2.1 Singapore's Standing
2.2 Operations Management
2.3 IHIS
2.4 EMR Governance
2.5 Drugs & Devices
2.6 Final Points
1. Banking and Finance Banks are one of the most – if not the most – regulated sectors in any country. That's because they're the repositories of finance, both personal and corporate, and maintaining trust in their operations and functions are vital to the running of the economy. In Singapore, the Monetary Authority of Singapore (MAS) is the country's Central Bank and financial regulator. MAS establishes rules for financial institutions which are implemented through legislation, regulations, directives, and notices. Guidelines have also been formulated to encourage best practices among financial institutions. These instruments (rules and guidelines) facilitate and promote desirable behaviour in financial institutions. These instruments – combined with close supervision – help MAS maintain a sound, progressive, trusted and respected financial services sector. In this context and given the increasing use of AI and data analytics (AIDA) in the financial services sector, MAS has laid out both general principles and operational guidance for the responsible use of AIDA by financial institutions.
1.
1. FEAT Principles On November 12, 2018, MAS published broad Principles to promote Fairness, Ethics, Accountability and Transparency (FEAT) in the use of AIDA in Singapore's financial services sector. The principles provide guidance to firms offering financial products and services on the responsible use of AI and data analytics, to strengthen internal governance in data management and use. --- Page 2 --- Page 2 of 14 This will foster greater confidence and trust in the use of AIDA, as firms increasingly adopt technology tools and solutions to support business strategies and in risk management. MAS has provided guidance on the ethics and accountability dimensions in the use of AI. Paragraph 4 of the MAS paper, Principles to Promote Fairness, Ethics, Accountability and Transparency (FEAT) in the Use of Artificial Intelligence and Data Analytics in Singapore's Financial Sector published November 12, 2018, offers a summary: a. Ethics Concerning ethics, organisations should ensure that:  Use of AIDA is aligned with the organisation's ethical standards, values and codes of conduct.  AIDA-driven decisions are held to the same ethical standards as human-driven decisions. b. Internal Accountability Concerning internal accountability, organisations should ensure that:  An appropriate internal authority approves use of AIDA in AIDA-driven decision- making.  Firms using AIDA are accountable for internally-developed and externally-sourced AIDA models.  Firms using AIDA proactively raise management and board awareness of their use of AIDA. c. External Accountability Concerning external accountability, organisations should ensure that:  Data subjects are provided with channels to enquire about, submit appeals for and request reviews of AIDA-driven decisions that affect them.  Verified and relevant supplementary data provided by data subjects are taken into account when reviewing AIDA-driven decisions. MAS guidelines note that the FEAT Principles "are not intended to be prescriptive" and are not "intended to replace existing relevant internal governance frameworks". However, MAS does recommend that financial institutions "consider (these principles) while assessing existing or developing new internal frameworks to govern the use of AIDA". Ultimately, every organisation should calibrate its actions and requirements under its internal governance framework based on the materiality of the AIDA-driven decision at hand. MAS has also provided some non-exhaustive and indicative considerations when assessing applicability:  The extent to which AIDA was used in decision-making.  The complexity of the AIDA model.  The extent of automation of AIDA-driven decision-making.  The severity and probability of impact on different stakeholders, including individuals.  The monetary and financial impact.  The regulatory impact.  Options for recourse available. --- Page 3 --- Page 3 of 14
1.
2. Veritas Initiative On November 13, 2019, MAS announced its "Veritas Initiative" to provide financial institutions with a verifiable way to incorporate relevant principles into their AIDA solutions. The Veritas consortium now has 17 members: MAS, DBS Bank, UOB, HSBC, EY, AXA, Standard Chartered Bank, Bank of China, BNP Paribas, BNY Mellon, Industrial and Commercial Bank of China, MUFG Bank, Ping An of China, Prudential Assurance, SGInnovate, Swiss Re, and Union Bank of the Philippines. Here are some salient points that MAS has outlined about the Veritas Initiative:  Veritas aims to provide financial institutions with a mathematically-verifiable way to incorporate the FEAT principles into their AIDA solutions.  Veritas will comprise open-source tools for use in different business lines, such as retail banking, corporate finance and foreign markets.  For a start, Veritas will focus on use-cases in three areas: customer marketing, risk scoring, and fraud detection.  Veritas will produce a report on its findings and conclusions.
1.
3. Digital Advisory Services On October 8, 2018, MAS issued Guidelines on Provision of Digital Advisory Services. Digital advisors (also known as robo-advisors) offer advice on investment products through direct access to automated, algorithm-based tools by clients. Robo-advisors have limited, or no human, advisor interaction. By contrast, conventional human financial advisors may rely on similar algorithm-based tools at the backend to help their representatives offer advice and service their clients. MAS generally treats robo-advisors with the same yardstick as a human financial advisor. This is applicable even at the regulatory level. For example, if the service provided is exempted from licensing for a human advisor, a similar exemption would also be enjoyed by a robo-advisor. However, MAS guidelines prescribe additional requirements for organisations deploying robo-advisory services. This is because of the unique and digital nature of robo-advisory services: --- Page 4 --- Page 4 of 14 a. Responsibility It is the responsibility of the board of directors and senior management of an organisation to maintain effective oversight and governance of robo-advisory services. b. Methodology For client-facing robo-advisory services, MAS mandates that robo-advisors should:  Ensure that the algorithm methodology behind the client-facing tool is robust.  Ensure that the tool collects all necessary information and analyses it to make suitable recommendations.  Have proper mechanisms to identify and resolve contradictory or inconsistent responses from clients.  Have controls in place (such as knock-out questions) to identify and eliminate clients who are unsuitable for investing.  Perform sufficient testing, before the launch of the tool and when changes are made to the instrument, to detect any error or bias in the algorithms and to consistently and reliably achieve the following key outcomes: o The algorithms should correctly classify clients according to their risk profiles based on inputs provided by them. In particular, the digital advisor should conduct back-testing using hypothetical inputs to ensure that the risk profiles generated by the algorithms are in line with its risk-profiling methodology. The testing must ensure that the algorithm scores and assigns risk profiles to clients correctly and consistently; o The algorithms should produce the intended asset allocation and investment recommendation, according to the digital advisor's risk profiling methodology. c. Disclosure Specifically, on information relating to algorithms, organisations are required to disclose in writing the following to clients minimally:  The assumptions, limitations and risks of AI algorithms.  The circumstances under which the digital advisors may override the algorithms or temporarily halt the digital advisory service.  The adjustments to the algorithms which may materially impact the outcome. --- Page 5 --- Page 5 of 14
2. Healthcare The healthcare sector probably has the second-highest level of government regulation and oversight; the first being banking and finance. From an ethical viewpoint, healthcare scores higher since it deals directly with human lives and well-being. This is embedded into the system right from the beginning, with every physician taking the Hippocratic Oath, and every nurse taking the Nightingale Pledge. The WHO adopted the Physician's Pledge in
1948. After several modifications, the Declaration is now a solemn oath taken by everyone joining the medical profession.
2.1 Singapore's Standing In Singapore, doctors must take the SMC Physician's Pledge to qualify for full registration in the SMC Register of Medical Practitioners. "Several lines in the pledge are easy to recognise as part of contemporary professional and clinical ethics," wrote Professor T Thirumoorthy, Executive Director, SMA Centre for Medical Ethics & Professionalism, in SMA News published in April
2015. "The sentence, 'Make the health of my patient my first consideration' fits in well with the principle of primacy of patient welfare and the importance of managing conflicts of interest (especially financial conflicts). The principle demands accepting that the interest of the patient is held above that of the clinician and other third parties, and is an essential component of building trust in the doctor-patient relationship." As for nurses, all graduating nurses need to take the Singapore Nursing Board's Nurse's Pledge. The first paragraph states that "In full knowledge of the obligations I am undertaking, I promise to provide a competent standard of care for the sick, regardless of race, religion and status, sparing no effort to alleviate suffering and promote health and to refrain from any action which might endanger life." Singapore has made considerable strides in healthcare. Its healthcare system was rated as the world's most efficient among 51 countries based on the cost of healthcare as a percentage of GDP, life expectancy, and healthcare cost per capita, according to a paper published in the US Journal of Patient Experience in November
2015. "Singapore's low healthcare expenditure of
4.5 per cent of its GDP is significantly less than that of the US, which is over 17 per cent of GDP. Moreover, Singapore boasts one of the lowest infant mortality rates of 2 deaths per 1,000 live births and the highest life expectancies of 85 years for women and 80 years for men." Even in the use of AI in healthcare, Singapore ranks high. "Among the 15 countries surveyed for the Future Health Index by Dutch technology company Royal Philips, Singapore had, at 28 per cent, the third-highest percentage of healthcare professionals who said they use AI to improve diagnostic accuracy," The Straits Times reported on June 20,
2019. "The figure is above the overall average of 21 per cent among the countries, but behind China's 45 per cent and Saudi Arabia's 34 per cent. Those with the lowest rates were the US with 10 per cent, and Australia and the Netherlands, with 8 per cent each." The concern? AI was used more for administrative tasks, with 37 per cent of respondents saying that they used it for functions such as staffing and scheduling patient appointments. Ms Caroline Clarke, Chief Executive of Philips ASEAN-Pacific, said this represented a missed opportunity to improve efficiency and accuracy in fields such as radiology. --- Page 6 --- Page 6 of 14 "She noted that AI could be used more in intensive care units, where it could help alert hospital staff to possible incidents quickly by detecting anomalies in patients' vital signs. That can help lower mortality rates. The survey showed that the use of AI for flagging patient anomalies in Singapore was also low, at 26 per cent," The Straits Times reported. Worldwide - as well as in Singapore - AI applications are being developed in:  Medical diagnostics.  Prescription recommendation.  Patient monitoring.  Learning systems.  Pharma drugs development.  Operations improvement.  Mining and managing medical data.
2.2 Operations Management a. CDSS CDSS stands for Clinical Decision Support Systems and focuses on clinical diagnosis and error reduction. CDSS is an IT application designed to provide physicians and other health professionals clinical decision support. A functional definition proposed by Robert Hayward of the Centre for Health Evidence is: "CDSS links health observations with health knowledge to influence health choices by clinicians for improved healthcare". CDSS is a significant component in AI use in medicine since the aim is to assist clinicians at the point-of-care using patient data. Clinicians can use an AI-enabled CDSS to provide diagnoses and predict treatment options based on clinical data, such as medical and social history, demographics, diagnostic tests, and other recorded information. Data can come from a patient's Electronic Medical Record (EMR) or Electronic Health Record (EHR). What's the difference? Both are digital records of patient health information, only different in scope.  An EMR is a digital version of a patient's chart and contains the patient's medical and treatment history from one practice, clinic, or hospital. The digital record stays in the doctor's office and does not get shared. If a patient switches doctors, his/her EMR is usually unlikely to follow.  An EHR contains the patient's records from multiple doctors and provides a more holistic, long-term view of a patient's health. It includes the patient's demographics, test results, medical history, history of present illness, and medications.  The National Electronic Health Record (NEHR) was set up in Singapore by Integrated Health Information Systems (IHIS) in
2011. The NEHR is a platform to collate all patient medical data with the aim to have "one patient, one health record". Owned by the Ministry of Health (MOH), the NEHR is managed by IHIS, and collects summary patient health records from different healthcare providers. This furnishes authorised healthcare professionals with a holistic view of their patients' healthcare history. Usually, medical data is recorded and updated in the patient's EHR. These data points, diagnoses and treatment outcomes can then be used to develop machine learning (ML) models, which in turn can be used with the EHR as a CDSS tool. --- Page 7 --- Page 7 of 14 The CDSS tool can make diagnostic recommendations based on algorithms that are programmed using rules set by established clinical guidelines and published medical research reviews. Diagnostic applications which have been proposed for CDSS include medical imaging analyses in cardiovascular diseases, stroke, fractures, diabetic retinopathy, and breast and skin cancers. It can also be used in the diagnosis of congenital cataract disease, Parkinson's disease and diabetes. AI has been demonstrated in some cases to be as accurate as, even faster than, an experienced clinician. While health system research can generate this type of knowledge, ML-based analytics in CDSS can speed up the process to deliver more efficient healthcare services in time to make a difference. These platforms can effectively close the loop between the care a patient gets, as documented in the EHR, and the healthcare provider. o Example: The European Union (EU) developed the Mosaic platform, which incorporates models and simulation techniques for discovering diabetes influence factors. The platform integrates datasets from hospitals and public health repositories to be analysed using advanced temporal analytics tools. o The information generated can be used to obtain deeper insights from diabetes monitoring, allow a better understanding of clinical issues, recognise novel phenotypes, inform clinical actions, and improve the efficiency of the healthcare system. While the project was on, people could use the "Citizen Tool" to calculate their risk of developing Type-2 diabetes in six years by filling a questionnaire. The tool uses AI algorithms to determine risk levels and make recommendations. o In Singapore, AI is being used to mine the text entries of doctors in emergency departments on the likelihood of a patient with stomach pains having appendicitis. Called "Discovery AI", it can predict such cases with up to 90 per cent accuracy. b. Ops Process Improvement The use of AI is more mundane in operations process improvement, as compared to patient care, but it can provide substantial efficiencies. Operations processes take time and effort that healthcare professionals can otherwise devote to patient care. For example, an average nurse can typically spend up to 25 per cent of work time on regulatory and administrative duties. One technology relevant to ops process management is robotic process automation (RPA). It can be used for a variety of applications in healthcare, including claims processing, clinical documentation, revenue cycle management and medical records management. RPA automates routine tasks, and AI is just about getting into some applications in RPA, such as in insurance. AI can also be used to expedite information delivery to clinicians, which is especially important in the current Covid-19 pandemic. A Covid-19 AI chatbot, allowing healthcare professionals to retrieve vital information quickly, was recently deployed on the National University Health System's intranet. o Example: AI can be used for probabilistic matching of data across various databases. Insurers need to verify that medical claims are correct. Reliably identifying, analysing and correcting coding issues and incorrect claims save all stakeholders – health insurers, governments and providers – a great deal of time, money and effort. It has also helped to flag outlier cases in fraud detection. o Another potential use of AI in administrative processes would be the auto-coding of diagnosis-related groups (DRG) which are coded manually. Currently, trained staff have to scrutinise the discharge summary record for claims with the government. This is time and labour intensive chore that would be ideal for an AI app to handle. --- Page 8 --- Page 8 of 14
2.3 IHIS All integrated hospitals in Singapore subscribe to a central data authority. Integrated Health Information Systems (IHIS) was set up in 2008 when staff from the IT wings of Singapore's healthcare clusters came together. The aim: to use technology to achieve service excellence and value, boost care delivery and improve patient care. IHIS is Singapore's technology agency for the public healthcare sector. It is tasked to digitise, connect, and analyse Singapore's health ecosystem. The aim is to boost the population's health and health administration by integrating intelligent and cost- effective technologies with process and people. The platform collates all patient medical data under the NEHR. The rationale: patients may visit multiple healthcare providers in their lifetime, including general practitioners (GPs), specialist clinics, therapy centres, and hospitals. Each provider has only a portion of patients' healthcare history. The NEHR collates it all into one central record. The datasets in the NEHR are focused only on a summary record of the patient's medical history. Summary care records are an electronic record of critical patient information, culled from GP medical records. They can be viewed or used only by authorised staff but will exclude doctors' case-notes from every consultation. The summary health records can be transmitted seamlessly from the providers' electronic system to the NEHR. The data could include patient demographics, diagnosis, discharge summary, medications prescribed, laboratory reports, radiology reports, allergies, immunisation records and operation theatre notes, procedures and treatments. The NEHR can be accessed only for caring patient care. IHIS says: "Use of NEHR for other purposes, including assessment for purposes of employment or insurance, will not be allowed, even with explicit patient consent." Another proposed change is the opt-out system. Previously, patients were allowed to opt- out of the NEHR after undergoing proper counselling. However, their information would still be uploaded to the system but not accessible to healthcare providers. With the change, patients who prefer not to have their information sent to the NEHR can be assessed on a case-by-case basis. "Patients would be advised on the consequences such as having a permanent gap in the NEHR, where their future care could be compromised even if they subsequently choose to opt back in," IHIS states on its website. o Example: AI was used to predict patient readmissions in IHIS. "We took all the discharge summaries, care plans, medications, specialist visit notes, and test results to predict who is likely to get readmitted after major surgeries such as cardiac bypass, thoracic surgery, and others," an IHIS executive noted. "We would titrate the medications, send a nurse to the patient within five days of discharge, monitor medications compliance, and check the patient's vitals, such as weight, blood pressure, heart rate and state of alertness each day for a week. That cut re-admissions by more than 60 per cent and was cited as the most successful AI pilot. We were able to predict with a LACE score of 86 per cent for factors leading to re-admissions. This procedure has since become commonplace and part of a clinical protocol for post- discharged patient care." --- Page 9 --- Page 9 of 14 o The LACE index helps to identify patients who are at risk of readmission or death within a month of discharge. The acronym stands for Length of stay during the initial hospitalisation; the Acuity of the admission, which is whether the patient was admitted through the A&E or came on his/her own; the Co-morbidities, or other complications such as diabetes, chronic hypertension, obesity, and others.; and how many Emergency department visits were required in the last six months. LACE scores range from 1-19; the higher the score, the greater the risk of re-admission. o Such cases, flagged as "frequent readmitters" are highlighted to the hospital's case managers. They could be more proactively managed to help families with future homecare needs and social rehabilitation programmes as early as possible, to avoid another re-admission to the hospital.
2.4 EMR Governance The EMR system is a crucial aspect of healthcare records governance. EMRs are electronic records that replace paper based-patient records. They provide real-time records that make information available instantly and securely to medical practitioners and administrative staff when required. For an embedded AI system to be used by clinicians, it must be deployed on the EMR system of the hospital or healthcare facility. That involves complying with the facility's set of regulations and governance processes, which would include the approval of both the medical board and EMR governance committees. Usually, the chief medical informatics officer (CMIO) has authority over this. o Example: Singapore researchers were looking at genetic tests of immunity – called Human Leukocyte Antigen (HLA) – to predict severe drug-related reactions in the Asian genome demographic, using AI. This project began as a collaboration between clinical researchers, clinicians, data scientists and IT staff. ML models showed that a specific HLA – B*1502, found commonly in Asians – reacted adversely with a drug called carbamazepine, causing life-threatening skin allergies; the clinical team validated this finding. Clinical guidelines were drawn up by MOH instructing that this HLA screening be done before drug initiation. Using a CDSS, the EMR would flag the need to screen for these tests when the drug is prescribed, or if the HLA genotype was already known to be abnormal. Obvious targets for AI using a CDSS are usually chronic and degenerative disease, where early diagnosis is critical to reduce complications, handle symptoms, and improve patient recovery. For example, AI can be used to predict the progression of diabetic kidney disease. It can analyse the data stored in the EHR on diabetic patients – including symptoms, physical exams, lab reports, medical history, treatments, outcomes – to either make predictions or diagnose patients with similar characteristics. (Source: Makino et al 2019). Similarly, the software can predict likely outcomes of treatments by including information that a physician may not readily have or be unaware of when recommending a treatment plan to the patient. The software can alert physicians to potential problems and conflicts with the proposed treatment plan, such as likely drug contraindications or efficacy issues, and allow the doctor to revise the treatment plan accordingly. (Source: AI-Assisted Decision-making in Healthcare published in the Asian Bioethics Review on September 12, 2019). --- Page 10 --- Page 10 of 14 In the above examples, here are some salient points: a. Data acquisition for model development. o All healthcare data should be managed ethically, with data privacy and security governance. o The datasets should be reviewed and tested to minimise the likelihood of bias. b. Explainability of the resultant model. o Clinicians should be notified of the factors that contributed to the model. o Authorised healthcare personnel should be allowed to see how the model scores patients. c. Technical testing procedures of the model during EMR deployment. o Testing should have minimal or no impact on the EMR's functioning. o Conduct tests to ensure the model is scoring patients as expected/programmed. d. Maintenance and tuning of the model. o Report the model performance on an agreed-upon frequency and schedule. o Adjust the model according to the clinical feedback. e. Patient-related outcomes due to action taken/decisions guided by the model. o Flag adverse effects of the model during testing or deployment. o Have an independent committee review all adverse test reports. In the course of patient care, clinical observations about patients are often entered directly into the EHR as unstructured narrative text. That data can be standardised for CDSS using natural language processing (NLP) that AI algorithms can understand. The system's accuracy rises when clinicians enter this information in a structured manner. Internal governance is needed to choose medical standards like SNOMED CT (diagnosis and drugs), LOINC (lab codes) or CPT (medical procedures). While this is the desired outcome, it is often onerous and time-consuming for clinicians to code everything; only a critical dataset should be coded in such a manner. The use of coded data in the EHR can drive more reliable recommendations in the CDSS for patient care. (Source: AI-Assisted Decision-making in Healthcare published in the Asian Bioethics Review on September 12, 2019). The new disruption in clinical care is the all-too-familiar complaint of physicians facing the computer screen more than talking to their patients. These problems have arisen due to the need for data entry in the EMR for clinical care and research. The clinician is torn between these demands and the need to devote time to his/her patients. These conflicts can be reduced if AI systems can be integrated into clinical care so that clinicians do not have to disrupt their work to key in duplicate or additional data for research use, The Journal of Law, Medicine & Ethics reported. For example, data entry tasks can be simplified using predictive text for diagnosis, investigations and treatment, or made more intuitive using speech recognition systems. --- Page 11 --- Page 11 of 14
2.5 Drugs & Devices a. HSA Singapore's Health Sciences Authority (HSA) was set up on April 1, 2001, when five specialised agencies under the Ministry of Health were integrated into one:  Centre for Drug Evaluation.  Institute of Science and Forensic Medicine.  National Pharmaceutical Administration  Product Regulation Department.  Singapore Blood Transfusion Service. HSA's wealth of knowledge, skills and competencies fall in three key groups:  Health Products Regulation Group.  Blood Services Group.  Applied Sciences Group. According to the WHO, a medical device can be any instrument, apparatus, implement, machine, appliance, implant, or a reagent for in-vitro use. That includes software, material or another similar or related article, intended to be used, alone or in combination, for human beings. Medical devices can be used for:  Diagnostic use, monitoring, treatment, and disease prevention or alleviation.  Determining diagnosis, treatment or compensation in case of an injury.  Investigation, replacement, modification, or support of the anatomy.  Supporting or sustaining life.  Control of conception.  Disinfection of medical devices.  Providing information about in vitro examination of specimens derived from the human body. In December 2019, HSA published its Regulatory Guidelines for Software Medical Devices – A Lifecycle Approach covering AI-enabled medical devices (AI-MDs). HSA urged device and software developers and implementers to comply with other regulations, including:  Personal Data Protection Act.  Human Biomedical Research Act.  Private Hospitals and Medical Clinics Act. "The regulatory principles for AI-MDs are comparable to software that is regulated as medical devices," HSA states on its website. "However, there are specific additional considerations such as continuous learning capabilities, level of human intervention, training of models, retraining, etc., for AI-MD that need to be considered carefully and addressed. All activities related to the design, development, training, validation, retraining and deployment of AI MD should be performed and managed under an ISO 13485 based quality management system." --- Page 12 --- Page 12 of 14 This diagram illustrates the process of developing and deploying an AI-MD: Figure 1: Process of developing and deploying an AI-MD (Source: HSA) Once AI-MDs are deployed in a real-world environment, active monitoring, review and tuning is necessary. HSA wants software developers and device sellers to set up a process with the physicians or nurses (implementers) and end-users (patients) to monitor, trace and review the performance – manually, autonomously or combining both – of the AI- MD deployed in clinical settings. This is to ensure that devices with continuous learning algorithms remain accurate and work as intended. All Singapore-registered AI-MDs are required by their vendors to monitor real-world performance post-deployment and submit periodic post-market reports to HSA. b. Drugs Discovery How much do drug companies spend on R&D to bring a new medicine or drug to market? About US$985 million, according to the latest study by the Journal of the American Medical Association (JAMA). The study, reported in the JAMA Network on March 3, 2020, included 63 of 355 new therapeutic drugs and biologic agents approved by the US Food and Drug Administration (FDA) between 2009 and
2018. "The estimated median capitalised R&D cost per product was US$985 million, counting expenditures on failed trials," the study reported. "Data was mainly accessible for smaller firms, products in certain therapeutic areas, orphan drugs, first-in-class drugs, therapeutic agents that received accelerated approval, and products approved between 2014 and
2018." Biopharmaceutical companies are taking notice of the efficiency, accuracy and knowledge that AI can provide. For instance:  Pfizer deploys IBM Watson, a system that uses ML, to power its search for immuno-oncology drugs.  Sanofi plans to use British start-up Exscientia's AI platform to seek metabolic- disease therapies.  Genentech uses an AI system from GNS Healthcare in Cambridge, Massachusetts, to help develop cancer treatments.  Most major biopharma companies have similar tie-ups or internal drug development initiatives. <|image_start|>bok_chapter_3_4_page12_img
1.jpeg<|image_end|> --- Page 13 --- Page 13 of 14 "If the proponents of these techniques are right, AI and ML will usher in an era of quicker, cheaper and more effective drug discovery," Nature reported on May 30,
2018. "Some are sceptical, but most experts expect these tools to become increasingly important. This shift presents both challenges and opportunities for scientists, especially when the techniques are combined with automation."
2.6 Final Points a. Do No Harm The medical profession's motto is: First, do no harm. That becomes complicated when AI is involved. AI can be likened to a driverless car; it has the potential to take over a physician's job. But what happens when harm occurs, or when the algorithm prescribes an incorrect treatment? Like the driverless car, the final responsibility may still rest on the clinician using these new AI-powered tools. b. Outcomes Deploying AI in medicine without adequate safeguards risks having adverse outcomes. These can be direct, such as when a wrong treatment or dosage is prescribed; or indirect, when AI uses data from a genetic profile and finds an individual to be more vulnerable to early dementia, for instance. Would this affect that individual psychologically, even though the event is predicted to happen in the distant future? Will it increase that individual's insurance premiums if the insurance company has access to this data? c. Jobs & Data AI in medicine can also impact specific jobs – such as those of radiologists and pathologists – when AI takes over reading scans and specimens, rendering sections of the profession obsolete. Moreover, AI needs vast amounts of data, from diverse sources, including genomic data which cannot be anonymised. Is it desirable to have a system with access to so much data? More so, when future discoveries can affect the present? What happens in the event of a data breach? d. Responsibility Who's responsible if something goes wrong? Singapore's approach has been to reinforce the importance of AI governance frameworks within hospitals and other organisations to mitigate or anticipate such problems. There are also regulatory boards which clarify and mandate levels of safety for AI systems that provide clinical decision support. If a lawsuit arises, patients should note that there are no standard regulations to assign liability to all the parties involved. For example, a misconfigured medical device may have many points of failure, including, but not limited to:  Device manufacturer (hardware-related).  Device functioning (software-related).  Supply chain (the distributor, wholesaler, retailer).  Implanter (the surgeon).  Monitoring parties (the primary care provider or nurse).  Drug contraindications (the pharmacist).  Unforeseen situations that impact the device (the patient going into cardiac arrest). When such cases come up for regulatory authorities or even courts to decide, they will be investigated from all angles to determine liability. That may likely be the situation if the manufacturers can justify their decisions, or if the hospital's AI governance framework is underdeveloped. In such cases, liability may be shared by all involved parties. --- Page 14 --- Page 14 of 14 e. Example A new AI tool, called RadiLogic, has been deployed at Singapore's National Centre for Infectious Diseases (NCID) to detect abnormal chest X-rays quickly. The tool can analyse an X-ray image in three seconds and highlight abnormal ones to help radiologists prioritise which images to review. It has an accuracy of up to 96 per cent. The screening centre saw up to 300 X-ray images a day during the peak of the pandemic in April 2020; the current rate is 100 images a day. "The AI tool is performing close to human capabilities, and it helps us prioritise the workflow to enhance our efficiency and diagnostic confidence," Adjunct Associate Professor Tan Cher Heng, Senior Consultant at Tan Tock Seng Hospital's (TTSH) Department of Diagnostic Radiology, told The Straits Times. He is also part of the team that developed the tool. Using deep learning, RadiLogic was fed 1,000 anonymised abnormal chest X-rays from Covid-19 patients, and 4,000 anonymised normal chest X- rays to train it to detect pneumonia accurately. The tool was developed by TTSH radiologists and researchers from A*Star's Institute of High-Performance Computing, and Institute for Infocomm Research. f. Research Although most AI-assisted CDSS tools are still being developed, as they gain acceptance in clinical practice, their capacity to perform ongoing research tasks will likely become less distinguishable as separate functions. One ethical implication of this blurring boundary is the dual-role that doctors will increasingly play as both clinical practitioners and researchers when interacting with a CDSS. g. Blame In an AI ethics issue, would MOH hold the hospital responsible, or its IT partner? Clinical care is the hospital's responsibility. MOH sets guidelines and regulations which are broad-based. The hospital clusters are responsible for outcomes and safety. So anything that can go wrong is found only at the tail-end – during the post-deployment phase, or at the forensics stage. There can be a slew of reasons for something going wrong; AI is not always to blame. The error could be due to the patient (genetic issues, poorly-managed chronic conditions, diet, etc), or at the physician's end (incorrect diagnosis, wrong prescriptions/dosage, poor judgement) or the hospital (a drop in hygiene standards, or hospital-acquired infections). h. Standards The medical profession could learn some lessons from the airline industry – which does a detailed post-crash analysis using data from the "black box" to determine if the crash was due to pilot's error, plane design, passenger non-compliance (opening the hatch), extreme weather, or other reasons. It could also get AI developers to incorporate quality standards such as TOGAF, COBIT, Six Sigma, Agile and DevOps. All of these steps will build more trust in AI, and in turn, engender greater acceptance in critical sectors such as banking and healthcare.